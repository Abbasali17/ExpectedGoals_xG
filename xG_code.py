# -*- coding: utf-8 -*-
"""Untitled77.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YUcp5RaDVpQoj9Ldau3vKliy9CGuGAc-
"""

!pip install mplsoccer xgboost scikit-learn pandas numpy matplotlib seaborn

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-
"""
Enhanced Expected Goals (xG) Model with Tracking Data (ISL 21/22)

This notebook replicates the xG model creation from the original
plot_xG_tracking.ipynb using ISL 21/22 data, but adds more
visualizations for EDA and model evaluation.
"""

# %% [markdown]
# # Enhanced Expected Goals (xG) Model with Tracking Data (ISL 21/22)
#
# This notebook builds an Expected Goals (xG) model incorporating player tracking data, based on the ISL 2021/22 dataset. It follows the feature engineering and modeling approach of the original `plot_xG_tracking.ipynb` but includes additional Exploratory Data Analysis (EDA) and improved visualizations.
#
# **Features Used:**
# - Ball location (x) (`x0`)
# - Angle to goal (`angle`)
# - Distance to goal (`distance`)
# - Binary: Ball closer to goal than GK (`is_closer`)
# - Ball-GK distance (`gk_distance`)
# - Ball-GK distance in y-axis (`gk_distance_y`)
# - Opponents in shooting triangle (`triangle`)
# - Opponents near the ball (<3m) (`close_players`)
# - Binary: Header shot (`header`)
# - Basic xG (logistic regression on angle/distance) (`xg_basic`)

# %% [code]
# Basic imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from mplsoccer import Pitch, Sbopen # Ensure installed: pip install mplsoccer
import statsmodels.api as sm
import statsmodels.formula.api as smf
import warnings
import os
import random as rn

# ML/DL Imports
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import roc_curve, roc_auc_score, brier_score_loss, log_loss, precision_recall_curve, auc
from sklearn.calibration import calibration_curve

# Setup
# %matplotlib inline
pd.options.mode.chained_assignment = None
warnings.filterwarnings('ignore')

# Reproducibility
SEED = 42
os.environ['PYTHONHASHSEED'] = str(SEED)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Hide TF info/warnings
np.random.seed(SEED)
rn.seed(SEED)
tf.random.set_seed(SEED)
# Optional: Configure TensorFlow to use deterministic operations if possible
# os.environ['TF_DETERMINISTIC_OPS'] = '1' # May slow down training

# %% [markdown]
# ## 1. Data Loading and Initial Filtering (Shots)
#
# Load StatsBomb event and tracking data for the ISL 2021/22 season. Filter for 'Shot' events and convert coordinates.

# %% [code]
start_time = time.time()

# Load data (ISL Dataset)
parser = Sbopen()
COMPETITION_ID = 1238
SEASON_ID = 108
df_match = parser.match(competition_id=COMPETITION_ID, season_id=SEASON_ID)
matches = df_match.match_id.unique()

all_events_df = pd.DataFrame()
all_tracking_df = pd.DataFrame() # Store all tracking data here

print(f"Processing {len(matches)} matches for Competition ID {COMPETITION_ID}, Season ID {SEASON_ID}...")
match_count = 0
for match_id in matches:
    match_count += 1
    if match_count % 10 == 0:
        print(f"  Processing match {match_count}/{len(matches)} (ID: {match_id})...")
    try:
        event_data = parser.event(match_id) # Returns list/tuple
        if len(event_data) < 3:
            print(f"  Warning: Match {match_id} missing tracking data? Skipping.")
            continue

        events = event_data[0].copy() # Main event data
        tracking_match = event_data[2].copy() # Tracking data

        # --- Coordinate Standardization ---
        pitch_length = 105
        pitch_width = 68
        statsbomb_length = 120
        statsbomb_width = 80

        if 'x' in events.columns: events['x'] = events['x'] * pitch_length / statsbomb_length
        if 'y' in events.columns: events['y'] = events['y'] * pitch_width / statsbomb_width
        # Apply also to shot end locations if they exist and are needed later
        if 'shot_end_location_x' in events.columns: events['shot_end_location_x'] = events['shot_end_location_x'] * pitch_length / statsbomb_length
        if 'shot_end_location_y' in events.columns: events['shot_end_location_y'] = events['shot_end_location_y'] * pitch_width / statsbomb_width

        if 'x' in tracking_match.columns: tracking_match['x'] = tracking_match['x'] * pitch_length / statsbomb_length
        if 'y' in tracking_match.columns: tracking_match['y'] = tracking_match['y'] * pitch_width / statsbomb_length
        # --- End Coordinate Standardization ---

        events['match_id'] = match_id
        if not tracking_match.empty:
            tracking_match['match_id'] = match_id

        # Append
        all_events_df = pd.concat([all_events_df, events], ignore_index=True)
        if not tracking_match.empty:
            all_tracking_df = pd.concat([all_tracking_df, tracking_match], ignore_index=True)

    except Exception as e:
        print(f"  Error processing match {match_id}: {e}")
        continue

loading_time = time.time() - start_time
print(f"\nFinished loading data in {loading_time:.2f} seconds.")

# Filter for Shots
shot_events_df = all_events_df[all_events_df["type_name"] == "Shot"].copy()
print(f"Total shot events found: {len(shot_events_df)}")
shot_events_df.dropna(subset=['x', 'y'], inplace=True) # Drop shots with missing location
print(f"Shot events after dropping NaN location: {len(shot_events_df)}")

# --- Visualization: Shot Type Distribution ---
plt.figure(figsize=(10, 5))
sns.countplot(data=shot_events_df, y='sub_type_name', order = shot_events_df['sub_type_name'].value_counts().index, palette='viridis')
plt.title('Distribution of Shot Sub-Types (Before Filtering)')
plt.xlabel('Count')
plt.ylabel('Shot Sub-Type')
plt.tight_layout()
plt.show()

# Filter for Open Play Shots
open_play_shots_df = shot_events_df[shot_events_df["sub_type_name"] == "Open Play"].copy()
print(f"Open play shots: {len(open_play_shots_df)}")

# --- Visualization: Open Play Shot Locations ---
pitch = Pitch(pitch_type='statsbomb', pitch_color='grass', line_color='white', stripe=True)
fig, ax = pitch.draw(figsize=(10, 7))
pitch.scatter(open_play_shots_df['x'], open_play_shots_df['y'], alpha=0.4, s=15, color='red', ax=ax)
ax.set_title('Locations of All Open Play Shots')
plt.show()


# %% [markdown]
# ## 2. Goalkeeper Tracking Filter
#
# Ensure that for the shots we consider, the opposition goalkeeper's position was tracked in the associated tracking data frame.

# %% [code]
if not all_tracking_df.empty:
    # Identify events (shots) where the opposition GK was tracked
    gks_tracked_ids = all_tracking_df[
        (all_tracking_df["teammate"] == False) &
        (all_tracking_df["position_name"] == "Goalkeeper")
    ]['id'].unique()

    shots_pre_filter_count = len(open_play_shots_df)
    shots_with_gk_df = open_play_shots_df[open_play_shots_df['id'].isin(gks_tracked_ids)].copy()
    shots_filtered_out = shots_pre_filter_count - len(shots_with_gk_df)

    print(f"Open play shots with tracked opponent GK: {len(shots_with_gk_df)}")
    print(f"(Filtered out {shots_filtered_out} shots due to missing GK tracking)")

    # --- Visualization: Compare Shots Before/After GK Filter ---
    fig, axs = plt.subplots(1, 2, figsize=(16, 7))
    pitch.draw(ax=axs[0])
    pitch.scatter(open_play_shots_df['x'], open_play_shots_df['y'], alpha=0.2, s=10, color='blue', ax=axs[0])
    axs[0].set_title('All Open Play Shots')

    pitch.draw(ax=axs[1])
    pitch.scatter(shots_with_gk_df['x'], shots_with_gk_df['y'], alpha=0.4, s=15, color='red', ax=axs[1])
    axs[1].set_title('Open Play Shots with Tracked GK (Final Set)')
    plt.suptitle('Shot Locations Before and After Goalkeeper Tracking Filter')
    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap
    plt.show()

    # Final dataframe for modeling
    df_model = shots_with_gk_df.reset_index(drop=True)
else:
    print("Error: Tracking data is empty. Cannot filter based on Goalkeeper tracking.")
    df_model = pd.DataFrame() # Ensure df_model is empty

# %% [markdown]
# ## 3. Feature Engineering & EDA on Features
#
# Calculate all features required for the model, including basic shot geometry, basic xG via logistic regression, and tracking-based features. Visualize the distributions and relationships of these features.

# %% [code]
feat_eng_start_time = time.time()

if not df_model.empty and not all_tracking_df.empty:
    print("\n--- Starting Feature Engineering ---")
    # Make a copy for feature engineering
    model_vars = df_model[['id', 'index', 'x', 'y', 'outcome_name', 'body_part_name', 'match_id', 'team_id']].copy() # Include team_id for helper funcs

    # Target Variable (Goal = 1, No Goal = 0)
    model_vars["goal"] = model_vars.outcome_name.apply(lambda cell: 1 if cell == "Goal" else 0)

    # Basic Geometry (relative to goal at (105, 34))
    model_vars["X_goal"] = pitch_length - model_vars["x"] # Distance to goal line
    model_vars["Y_goal_abs"] = abs(pitch_width/2 - model_vars["y"]) # Absolute distance from center y

    # Angle and Distance (Using the formula from original notebook)
    # Ensure no division by zero or invalid values inside sqrt/arctan
    # Clamp values to avoid math errors with shots exactly on goal line or posts
    x_adj = np.maximum(0.01, model_vars["X_goal"]) # Avoid X=0
    y_adj_sq = model_vars["Y_goal_abs"]**2
    goal_width = 7.32
    term_in_arctan = (goal_width * x_adj) / (x_adj**2 + y_adj_sq - (goal_width/2)**2)
    # Handle cases where the denominator might make term_in_arctan undefined or cause issues
    # We assume shots are outside the goal mouth physical space for angle calculation
    model_vars["angle"] = np.arctan(np.maximum(term_in_arctan, -1e9)) # Use maximum to avoid large negatives if inside goal?
    model_vars["angle"] = np.where(model_vars["angle"] < 0, model_vars["angle"] + np.pi, model_vars["angle"]) # Adjust angles to be [0, pi]
    model_vars["angle_degrees"] = model_vars["angle"] * 180 / np.pi # Convert to degrees for intuition
    model_vars["distance"] = np.sqrt(x_adj**2 + y_adj_sq)

    # --- Calculate Basic Logistic Regression xG ('xg_basic') ---
    print("Calculating basic xG model...")
    log_reg_model = smf.glm(formula="goal ~ angle + distance", data=model_vars,
                               family=sm.families.Binomial()).fit()
    # print(log_reg_model.summary()) # Optional: Print summary
    model_vars["xg_basic"] = log_reg_model.predict(model_vars)
    print("Basic xG calculation complete.")

    # --- Tracking-Based Features ---
    print("Calculating tracking-based features (this may take time)...")
    tracking_calc_start_time = time.time()

    # Group tracking data for faster lookups
    tracking_grouped = all_tracking_df.groupby(['match_id', 'id'])

    # Helper functions (adapted slightly for clarity/efficiency)
    def get_tracking_slice(event_id, match_id, grouped_data):
        try:
            return grouped_data.get_group((match_id, event_id))
        except KeyError:
            return pd.DataFrame() # Return empty if event not in tracking

    def dist_to_gk(shot_row, grouped_tracking):
        tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
        if tracking_slice.empty: return np.nan
        gk_pos = tracking_slice[(tracking_slice['teammate'] == False) & (tracking_slice['position_name'] == 'Goalkeeper')]
        if gk_pos.empty: return np.nan
        gk_x, gk_y = gk_pos.iloc[0]['x'], gk_pos.iloc[0]['y']
        dist = np.sqrt((shot_row['x'] - gk_x)**2 + (shot_row['y'] - gk_y)**2)
        return dist

    def y_dist_to_gk(shot_row, grouped_tracking):
        tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
        if tracking_slice.empty: return np.nan
        gk_pos = tracking_slice[(tracking_slice['teammate'] == False) & (tracking_slice['position_name'] == 'Goalkeeper')]
        if gk_pos.empty: return np.nan
        gk_y = gk_pos.iloc[0]['y']
        dist = abs(shot_row['y'] - gk_y)
        return dist

    def num_opp_near_ball(shot_row, grouped_tracking, radius=3):
        tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
        if tracking_slice.empty: return 0
        opponents = tracking_slice[tracking_slice['teammate'] == False]
        if opponents.empty: return 0
        distances = np.sqrt((shot_row['x'] - opponents['x'])**2 + (shot_row['y'] - opponents['y'])**2)
        return (distances < radius).sum()

    def players_in_triangle(shot_row, grouped_tracking):
        tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
        if tracking_slice.empty: return 0
        opponents = tracking_slice[tracking_slice['teammate'] == False]
        if opponents.empty: return 0

        # Triangle vertices: Shot location, Goal post 1, Goal post 2
        p1 = np.array([shot_row['x'], shot_row['y']])
        p2 = np.array([pitch_length, pitch_width/2 - goal_width/2]) # Goal post 1
        p3 = np.array([pitch_length, pitch_width/2 + goal_width/2]) # Goal post 2

        # Barycentric coordinate system check (is point P inside triangle V1, V2, V3?)
        # Vector math: v0 = p3-p1, v1 = p2-p1, v2 = P-p1
        # Check if P = p1 + u*v1 + v*v0, where u>=0, v>=0, u+v<=1
        def is_inside(point, v1, v2, v3):
             p = point
             d = (v2[1] - v3[1]) * (v1[0] - v3[0]) + (v3[0] - v2[0]) * (v1[1] - v3[1])
             if abs(d) < 1e-9: return False # Avoid division by zero if triangle is degenerate
             w1 = ((v2[1] - v3[1]) * (p[0] - v3[0]) + (v3[0] - v2[0]) * (p[1] - v3[1])) / d
             w2 = ((v3[1] - v1[1]) * (p[0] - v3[0]) + (v1[0] - v3[0]) * (p[1] - v3[1])) / d
             w3 = 1.0 - w1 - w2
             return (0 <= w1 <= 1) and (0 <= w2 <= 1) and (0 <= w3 <= 1)

        count = 0
        for _, opp in opponents.iterrows():
            opp_point = np.array([opp['x'], opp['y']])
            if is_inside(opp_point, p1, p2, p3):
                count += 1
        return count

    def gk_dist_to_goal_center(shot_row, grouped_tracking):
        tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
        if tracking_slice.empty: return np.nan
        gk_pos = tracking_slice[(tracking_slice['teammate'] == False) & (tracking_slice['position_name'] == 'Goalkeeper')]
        if gk_pos.empty: return np.nan
        gk_x, gk_y = gk_pos.iloc[0]['x'], gk_pos.iloc[0]['y']
        dist = np.sqrt((pitch_length - gk_x)**2 + (pitch_width/2 - gk_y)**2) # Dist to center of goal line
        return dist

    # Apply functions (can take a while)
    model_vars['gk_distance'] = model_vars.apply(dist_to_gk, grouped_tracking=tracking_grouped, axis=1)
    model_vars['gk_distance_y'] = model_vars.apply(y_dist_to_gk, grouped_tracking=tracking_grouped, axis=1)
    model_vars['close_players'] = model_vars.apply(num_opp_near_ball, grouped_tracking=tracking_grouped, radius=3, axis=1)
    model_vars['triangle'] = model_vars.apply(players_in_triangle, grouped_tracking=tracking_grouped, axis=1)
    model_vars['gk_dist_to_goal'] = model_vars.apply(gk_dist_to_goal_center, grouped_tracking=tracking_grouped, axis=1)

    # Handle potential NaNs from tracking calculations (e.g., if GK missing despite initial filter)
    model_vars['gk_distance'].fillna(model_vars['gk_distance'].median(), inplace=True)
    model_vars['gk_distance_y'].fillna(model_vars['gk_distance_y'].median(), inplace=True)
    model_vars['gk_dist_to_goal'].fillna(model_vars['gk_dist_to_goal'].median(), inplace=True)

    # Derived tracking features
    model_vars['is_closer'] = np.where(model_vars['gk_dist_to_goal'] > model_vars['distance'], 1, 0)

    # Other features
    model_vars['header'] = model_vars.body_part_name.apply(lambda cell: 1 if cell == "Head" else 0)
    model_vars['x0'] = model_vars.x # Keep original x coordinate as a feature

    print(f"Tracking features calculated in {(time.time() - tracking_calc_start_time):.2f} seconds.")

    # --- EDA on Engineered Features ---
    print("\n--- EDA on Engineered Features ---")

    # 1. Distributions of Key Continuous Features by Goal Outcome
    features_to_plot = ['angle_degrees', 'distance', 'xg_basic', 'gk_distance', 'gk_distance_y',
                        'gk_dist_to_goal', 'close_players', 'triangle']
    plt.figure(figsize=(15, 12))
    for i, col in enumerate(features_to_plot):
        plt.subplot(3, 3, i + 1)
        sns.kdeplot(data=model_vars, x=col, hue='goal', fill=True, common_norm=False, palette='coolwarm', alpha=0.5)
        plt.title(f'Distribution of {col}')
        plt.ylabel('Density')
    plt.tight_layout()
    plt.show()

    # 2. Counts of Binary/Categorical Features by Goal Outcome
    binary_features = ['is_closer', 'header']
    plt.figure(figsize=(12, 4))
    for i, col in enumerate(binary_features):
        plt.subplot(1, 2, i + 1)
        sns.countplot(data=model_vars, x=col, hue='goal', palette='coolwarm')
        plt.title(f'Count of {col} by Goal Outcome')
    plt.tight_layout()
    plt.show()

    # 3. Correlation Heatmap (including new features)
    corr_features = ['goal', 'angle', 'distance', 'xg_basic', 'gk_distance', 'gk_distance_y',
                     'close_players', 'triangle', 'gk_dist_to_goal', 'is_closer', 'header', 'x0']
    # Ensure only columns present in model_vars are used
    corr_features_exist = [f for f in corr_features if f in model_vars.columns]
    corr_matrix = model_vars[corr_features_exist].corr()
    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
    plt.title('Correlation Matrix of Features')
    plt.show()

    # 4. Shot Map colored by Number of Players in Triangle
    plt.figure(figsize=(10, 7))
    pitch = Pitch(pitch_type='statsbomb', pitch_color='grass', line_color='white', stripe=True)
    fig, ax = pitch.draw(figsize=(10, 7))
    sc = pitch.scatter(model_vars['x'], model_vars['y'], c=model_vars['triangle'], cmap='viridis', s=20, ax=ax)
    cbar = fig.colorbar(sc, ax=ax)
    cbar.set_label('Number of Opponents in Triangle')
    ax.set_title('Shot Locations Colored by Opponents in Triangle')
    plt.show()


    print(f"--- Feature Engineering & EDA Finished ({(time.time() - feat_eng_start_time):.2f} seconds) ---")

else:
    print("\nSkipping Feature Engineering as input dataframes (df_model or all_tracking_df) are empty.")
    model_vars = pd.DataFrame() # Ensure empty for downstream


# %% [markdown]
# ## 4. Data Preparation for Model
#
# Select the final features, define the target variable, split the data into training, validation, and test sets, and scale the features.

# %% [code]
if not model_vars.empty:
    # Define features (X) and target (y)
    feature_names = ["x0", "is_closer", "angle", "distance", "gk_distance",
                     "gk_distance_y", "triangle", "close_players", "header", "xg_basic"]
    X = model_vars[feature_names].values
    y = model_vars["goal"].values

    print(f"Feature matrix shape: {X.shape}")
    print(f"Target vector shape: {y.shape}")

    # Split data: 70% train, 15% validation, 15% test
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp)

    print(f"Train samples: {len(X_train)}")
    print(f"Validation samples: {len(X_val)}")
    print(f"Test samples: {len(X_test)}")

    # Scale data
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_val = scaler.transform(X_val)
    X_test = scaler.transform(X_test)
    print("Data scaling complete.")
else:
    print("Skipping Data Preparation as model_vars is empty.")

# %% [markdown]
# ## 5. Model Definition & Training (Keras Neural Network)
#
# Define and train the shallow neural network using Keras, similar to the original notebook. Optimize for Mean Squared Error (Brier Score).

# %% [code]
if 'X_train' in locals(): # Check if data preparation was successful
    model_train_start_time = time.time()
    print("\n--- Defining and Training Neural Network Model ---")

    # Define model architecture
    def create_model(input_shape):
        model = Sequential([
            Dense(10, activation='relu', input_shape=(input_shape,)),
            Dense(10, activation='relu'),
            Dense(1, activation='sigmoid'), # Output probability
        ])
        # Compile using Adam optimizer and MSE loss (equivalent to Brier score for binary 0/1 target)
        opt = Adam(learning_rate=0.001) # Default betas are fine
        model.compile(optimizer=opt, loss="mean_squared_error", metrics=['binary_accuracy']) # Use binary_accuracy for intuition
        return model

    # Create the model
    input_dim = X_train.shape[1]
    model = create_model(input_dim)
    print(model.summary())

    # Define Early Stopping callback
    # Monitor validation loss, restore best weights
    early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=50,
                                   verbose=1, mode='min', restore_best_weights=True)

    # Train the model
    BATCH_SIZE = 32 # Increased batch size slightly
    EPOCHS = 500 # Max epochs, early stopping will likely trigger sooner

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        callbacks=[early_stopping],
        verbose=1 # Set to 1 or 2 to see epoch progress, 0 for silent
    )

    print(f"--- Model Training Finished ({(time.time() - model_train_start_time):.2f} seconds) ---")

    # --- Visualization: Training History ---
    hist_df = pd.DataFrame(history.history)
    fig, axs = plt.subplots(1, 2, figsize=(14, 5))

    # Plot Loss
    axs[0].plot(hist_df['loss'], label='Train Loss')
    axs[0].plot(hist_df['val_loss'], label='Validation Loss')
    axs[0].set_title('Model Loss (MSE / Brier Score)')
    axs[0].set_xlabel('Epoch')
    axs[0].set_ylabel('Loss')
    axs[0].legend()
    axs[0].grid(True, alpha=0.3)
    # Highlight best epoch
    best_epoch = np.argmin(hist_df['val_loss'])
    axs[0].axvline(best_epoch, color='r', linestyle='--', label=f'Best Epoch ({best_epoch+1})')
    axs[0].legend()


    # Plot Accuracy
    axs[1].plot(hist_df['binary_accuracy'], label='Train Accuracy')
    axs[1].plot(hist_df['val_binary_accuracy'], label='Validation Accuracy')
    axs[1].set_title('Model Accuracy')
    axs[1].set_xlabel('Epoch')
    axs[1].set_ylabel('Accuracy')
    axs[1].legend()
    axs[1].grid(True, alpha=0.3)
    # Highlight epoch with best validation accuracy
    best_acc_epoch = np.argmax(hist_df['val_binary_accuracy'])
    axs[1].axvline(best_acc_epoch, color='g', linestyle='--', label=f'Best Acc Epoch ({best_acc_epoch+1})')
    axs[1].legend()


    plt.tight_layout()
    plt.show()

else:
    print("Skipping Model Training as prepared data (X_train) is not available.")

# %% [markdown]
# ## 6. Model Evaluation on Test Set
#
# Evaluate the trained model's performance on the unseen test set using various metrics and visualizations.

# %% [code]
if 'model' in locals() and 'X_test' in locals(): # Check if model and test data exist
    model_eval_start_time = time.time()
    print("\n--- Evaluating Model on Test Set ---")

    # Predict probabilities on the test set
    y_pred_proba = model.predict(X_test).flatten() # Flatten to 1D array
    y_pred_class = (y_pred_proba > 0.5).astype(int) # Class prediction based on 0.5 threshold

    # --- Calculate Metrics ---
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    brier = brier_score_loss(y_test, y_pred_proba)
    logloss = log_loss(y_test, y_pred_proba) # Use log loss for probabilities
    accuracy = np.mean(y_pred_class == y_test)

    print(f"Test Set Metrics:")
    print(f"  ROC AUC: {roc_auc:.4f}")
    print(f"  Brier Score: {brier:.4f}")
    print(f"  Log Loss: {logloss:.4f}")
    print(f"  Accuracy: {accuracy:.4f}")

    # --- Visualizations ---
    fig, axs = plt.subplots(2, 2, figsize=(14, 12))

    # 1. ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    axs[0, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')
    axs[0, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance')
    axs[0, 0].set_xlim([0.0, 1.0])
    axs[0, 0].set_ylim([0.0, 1.05])
    axs[0, 0].set_xlabel('False Positive Rate')
    axs[0, 0].set_ylabel('True Positive Rate')
    axs[0, 0].set_title('Receiver Operating Characteristic (ROC)')
    axs[0, 0].legend(loc="lower right")
    axs[0, 0].grid(alpha=0.3)

    # 2. Precision-Recall Curve
    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
    pr_auc = auc(recall, precision)
    axs[0, 1].plot(recall, precision, color='blue', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')
    baseline = y_test.mean() # Baseline: ratio of positive class
    axs[0, 1].axhline(baseline, ls='--', color='grey', label=f'Baseline ({baseline:.3f})')
    axs[0, 1].set_xlabel('Recall')
    axs[0, 1].set_ylabel('Precision')
    axs[0, 1].set_title('Precision-Recall Curve')
    axs[0, 1].legend(loc="upper right")
    axs[0, 1].grid(alpha=0.3)
    axs[0, 1].set_ylim([0.0, 1.05])
    axs[0, 1].set_xlim([0.0, 1.0])

    # 3. Calibration Curve
    prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10, strategy='uniform')
    axs[1, 0].plot(prob_pred, prob_true, marker='o', linestyle='-', label='Model Calibration', color='red')
    axs[1, 0].plot([0, 1], [0, 1], linestyle='--', color='black', label='Perfectly Calibrated')
    axs[1, 0].set_xlabel('Mean Predicted Probability (Bin)')
    axs[1, 0].set_ylabel('Fraction of Positives (Bin)')
    axs[1, 0].set_title('Calibration Curve')
    axs[1, 0].legend()
    axs[1, 0].grid(alpha=0.3)

    # 4. Distribution of Predicted Probabilities (xG)
    sns.histplot(y_pred_proba[y_test==0], color="red", label="No Goal", kde=True, stat="density", linewidth=0, alpha=0.4, ax=axs[1, 1])
    sns.histplot(y_pred_proba[y_test==1], color="blue", label="Goal", kde=True, stat="density", linewidth=0, alpha=0.4, ax=axs[1, 1])
    axs[1, 1].set_title('Distribution of Predicted xG Values by Outcome')
    axs[1, 1].set_xlabel('Predicted xG Probability')
    axs[1, 1].legend()
    # axs[1, 1].set_xlim(0, 1) # Ensure x-axis is 0 to 1

    plt.tight_layout()
    plt.show()

    print(f"--- Model Evaluation Finished ({(time.time() - model_eval_start_time):.2f} seconds) ---")

else:
    print("Skipping Model Evaluation as model or test data is not available.")


# %% [markdown]
# ## 7. Qualitative Analysis & Examples
#
# Visualize specific examples from the test set on a pitch, showing player positions from tracking data and the model's predicted xG. This helps understand *why* the model assigns certain probabilities.

# %% [code]
if 'model' in locals() and 'X_test' in locals() and not model_vars.empty and 'tracking_grouped' in locals():
    analysis_start_time = time.time()
    print("\n--- Qualitative Analysis: Plotting Example Shots ---")

    # Get original indices of test set back into model_vars
    test_indices = model_vars.iloc[X_temp.index[len(X_val):]].index # Indices for X_test within original model_vars
    test_data_orig = model_vars.loc[test_indices].copy()
    test_data_orig['predicted_xg'] = y_pred_proba

    # Find examples: Highest xG miss, Lowest xG goal
    highest_xg_miss = test_data_orig[test_data_orig['goal'] == 0].sort_values('predicted_xg', ascending=False).iloc[0:3] # Top 3
    lowest_xg_goal = test_data_orig[test_data_orig['goal'] == 1].sort_values('predicted_xg', ascending=True).iloc[0:3] # Top 3

    examples_to_plot = pd.concat([highest_xg_miss, lowest_xg_goal])

    pitch = Pitch(pitch_type='statsbomb', pitch_color='#22312b', line_color='#c7d5cc', constrained_layout=False, tight_layout=True)

    for i, shot_info in examples_to_plot.iterrows():
        match_id = shot_info['match_id']
        event_id = shot_info['id']
        goal_outcome = "GOAL" if shot_info['goal'] == 1 else "No Goal"

        try:
            tracking_slice = tracking_grouped.get_group((match_id, event_id))

            fig, ax = pitch.draw(figsize=(12, 8))
            fig.set_facecolor('#22312b')

            # Plot players
            teammates_track = tracking_slice[tracking_slice['teammate']]
            opponents_track = tracking_slice[~tracking_slice['teammate']]
            pitch.scatter(teammates_track['x'], teammates_track['y'], c='blue', edgecolors='w', s=150, label='Shooter Team', ax=ax, zorder=3)
            pitch.scatter(opponents_track['x'], opponents_track['y'], c='red', edgecolors='w', s=150, label='Opponent Team', ax=ax, zorder=3)

            # Highlight shooter
            shooter_x, shooter_y = shot_info['x'], shot_info['y']
            pitch.scatter(shooter_x, shooter_y, c='yellow', edgecolors='k', s=250, marker='*', label='Shooter', ax=ax, zorder=4)

            # Line to center of goal
            pitch.lines(shooter_x, shooter_y, pitch_length, pitch_width/2, color='yellow', lw=2, ls='--', ax=ax, label='Shot Path', zorder=2)

            # Add title
            title_text = (f"Example Shot: Match {match_id}, Event {event_id}\n"
                          f"Shooter: {shot_info.get('player_name', 'N/A')} ({shot_info.get('team_name', 'N/A')})\n"
                          f"Outcome: {goal_outcome}, Predicted xG: {shot_info['predicted_xg']:.3f}")
            ax.set_title(title_text, color='white', fontsize=14)
            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), facecolor='grey', edgecolor='white', labelcolor='white')
            plt.show()

        except KeyError:
            print(f"Warning: Could not find tracking data for example shot (Match {match_id}, Event {event_id}). Skipping plot.")
        except Exception as e:
            print(f"Error plotting example shot (Match {match_id}, Event {event_id}): {e}")

    print(f"--- Qualitative Analysis Finished ({(time.time() - analysis_start_time):.2f} seconds) ---")
else:
    print("Skipping Qualitative Analysis as prerequisites are missing.")


# %% [markdown]
# ## 8. (Optional) Application on New Data (Euro 2020 Example)
#
# Apply the trained model (including the scaler) to a different dataset (e.g., Euro 2020) to calculate xG values. Note: Euro 2020 uses freeze frames, so tracking features need careful adaptation or omission if not directly comparable. *For simplicity here, we might need to skip some tracking features or use default values if applying to Euro.*
#
# **Note:** Due to the differences in tracking data availability (ISL tracking vs Euro freeze frames), directly applying all tracking features might be problematic. A robust application would require recalculating features based *only* on freeze frames for the Euro data, or training a separate model. This section is illustrative and may require adjustments.

# %% [code]
# --- Optional Section ---
# Commenting out for now as applying ISL tracking features to Euro freeze frames requires careful adaptation.
"""
apply_start_time = time.time()
print("\n--- Optional: Applying Model to Euro 2020 (Illustrative) ---")

# Load Euro 2020 Data (Events and Freeze Frames)
parser_euro = Sbopen()
df_match_euro = parser_euro.match(competition_id=55, season_id=43)
matches_euro = df_match_euro.match_id.unique()

shots_euro_df = pd.DataFrame()
freeze_euro_df = pd.DataFrame()
# ... [Code to load Euro events and freeze frames, similar to Section 1 but for Euro] ...
# ... [Filter for Open Play Shots] ...

# --- Feature Engineering for Euro Data ---
# CRITICAL: Need to recalculate features using ONLY freeze frame data or omit ISL-specific tracking features.
# This requires adapting the helper functions or creating new ones for freeze frames.
# Example: gk_distance from freeze frame, num opponents near ball from freeze frame, etc.
# For illustration, assume we calculate a subset of features available from events/freeze frames:
# model_vars_euro = euro_shots[['id', 'x', 'y', ...]]
# model_vars_euro["goal"] = ...
# model_vars_euro["X_goal"] = ...
# model_vars_euro["Y_goal_abs"] = ...
# model_vars_euro["angle"] = ...
# model_vars_euro["distance"] = ...
# model_vars_euro["header"] = ...
# model_vars_euro['x0'] = model_vars_euro.x

# --- Create Dummy/Approximate Tracking Features ---
# !! This is a placeholder - real application needs proper feature recalculation !!
# Example: Assume default values or simpler calculations if direct mapping isn't feasible
# model_vars_euro['gk_distance'] = 15 # Placeholder
# model_vars_euro['gk_distance_y'] = 5  # Placeholder
# model_vars_euro['close_players'] = 1 # Placeholder
# model_vars_euro['triangle'] = 2      # Placeholder
# model_vars_euro['gk_dist_to_goal'] = 10 # Placeholder
# model_vars_euro['is_closer'] = np.where(model_vars_euro['gk_dist_to_goal'] > model_vars_euro['distance'], 1, 0)
# model_vars_euro['xg_basic'] = log_reg_model.predict(model_vars_euro) # Use original basic model

# --- Predict using ISL Model ---
# if not model_vars_euro.empty:
#    X_euro = model_vars_euro[feature_names].values # Use same feature order
#    # Handle potential NaNs in Euro features before scaling
#    # ... NaN handling ...
#    X_euro_scaled = scaler.transform(X_euro) # Use the SCALER FITTED ON ISL DATA
#    xg_euro_predicted = model.predict(X_euro_scaled).flatten()
#    model_vars_euro['our_xG'] = xg_euro_predicted

#    # Aggregate and Display Results
#    player_xg_euro = model_vars_euro.groupby('player_name')['our_xG'].sum().sort_values(ascending=False)
#    print("\nTop 5 Players by Predicted xG (Euro 2020 - Illustrative):")
#    print(player_xg_euro.head(5))

#    # --- Visualization: Top Players xG Bar Chart ---
#    plt.figure(figsize=(10, 6))
#    top_players = player_xg_euro.head(10)
#    sns.barplot(x=top_players.values, y=top_players.index, palette='magma')
#    plt.title('Top 10 Players by Aggregated xG (Euro 2020 - Illustrative)')
#    plt.xlabel('Total Predicted xG')
#    plt.ylabel('Player Name')
#    plt.show()

# else:
#    print("Skipping Euro application due to empty data or feature calculation issues.")

# print(f"--- Euro Application Finished ({(time.time() - apply_start_time):.2f} seconds) ---")
"""
print("\nSkipping Optional Euro 2020 Application section.")

# %% [markdown]
# ## 9. Conclusion
#
# Summarize the findings from the enhanced xG model. Discuss the impact of tracking features, model performance (AUC, Brier, Calibration), and insights gained from the improved visualizations and qualitative examples. Potential next steps could include trying different model architectures, adding more sophisticated tracking features (e.g., player velocity, line-breaking passes leading to the shot), or applying the model for player/team evaluation.

# %% [code]
print("\n--- Notebook Execution Complete ---")
total_runtime = time.time() - start_time
print(f"Total Runtime: {total_runtime:.2f} seconds ({total_runtime/60:.2f} minutes)")

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-
"""
Enhanced Expected Goals (xG) Model with Tracking Data (ISL 21/22)

This notebook replicates the xG model creation from the original
plot_xG_tracking.ipynb using ISL 21/22 data, but adds more
visualizations for EDA and model evaluation, and saves the plots.
"""

# %% [markdown]
# # Enhanced Expected Goals (xG) Model with Tracking Data (ISL 21/22)
#
# This notebook builds an Expected Goals (xG) model incorporating player tracking data, based on the ISL 2021/22 dataset. It follows the feature engineering and modeling approach of the original `plot_xG_tracking.ipynb` but includes additional Exploratory Data Analysis (EDA) and improved visualizations. Plots generated will be saved to a subdirectory.
#
# **Features Used:**
# - Ball location (x) (`x0`)
# - Angle to goal (`angle`)
# - Distance to goal (`distance`)
# - Binary: Ball closer to goal than GK (`is_closer`)
# - Ball-GK distance (`gk_distance`)
# - Ball-GK distance in y-axis (`gk_distance_y`)
# - Opponents in shooting triangle (`triangle`)
# - Opponents near the ball (<3m) (`close_players`)
# - Binary: Header shot (`header`)
# - Basic xG (logistic regression on angle/distance) (`xg_basic`)

# %% [code]
# Basic imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from mplsoccer import Pitch, Sbopen # Ensure installed: pip install mplsoccer
import statsmodels.api as sm
import statsmodels.formula.api as smf
import warnings
import os
import random as rn
import time

# ML/DL Imports
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import roc_curve, roc_auc_score, brier_score_loss, log_loss, precision_recall_curve, auc
from sklearn.calibration import calibration_curve

# Setup
# %matplotlib inline
pd.options.mode.chained_assignment = None
warnings.filterwarnings('ignore')

# Reproducibility
SEED = 42
os.environ['PYTHONHASHSEED'] = str(SEED)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Hide TF info/warnings
np.random.seed(SEED)
rn.seed(SEED)
tf.random.set_seed(SEED)
# Optional: Configure TensorFlow to use deterministic operations if possible
# os.environ['TF_DETERMINISTIC_OPS'] = '1' # May slow down training

# --- Directory for Saving Plots ---
plot_dir = "xg_model_plots_isl" # Renamed slightly for clarity
os.makedirs(plot_dir, exist_ok=True)
print(f"Plots will be saved in directory: '{plot_dir}'")
# --- End ---

# %% [markdown]
# ## 1. Data Loading and Initial Filtering (Shots)
#
# Load StatsBomb event and tracking data for the ISL 2021/22 season. Filter for 'Shot' events and convert coordinates.

# %% [code]
start_time_notebook = time.time()
start_time_section = time.time()

# Load data (ISL Dataset)
parser = Sbopen()
COMPETITION_ID = 1238
SEASON_ID = 108
df_match = parser.match(competition_id=COMPETITION_ID, season_id=SEASON_ID)
matches = df_match.match_id.unique()

all_events_df = pd.DataFrame()
all_tracking_df = pd.DataFrame() # Store all tracking data here

print(f"Processing {len(matches)} matches for Competition ID {COMPETITION_ID}, Season ID {SEASON_ID}...")
match_count = 0
for match_id in matches:
    match_count += 1
    if match_count % 10 == 0:
        print(f"  Processing match {match_count}/{len(matches)} (ID: {match_id})...")
    try:
        event_data = parser.event(match_id) # Returns list/tuple
        if len(event_data) < 3:
            print(f"  Warning: Match {match_id} missing tracking data? Skipping.")
            continue

        events = event_data[0].copy() # Main event data
        tracking_match = event_data[2].copy() # Tracking data

        # --- Coordinate Standardization ---
        pitch_length = 105
        pitch_width = 68
        statsbomb_length = 120
        statsbomb_width = 80

        if 'x' in events.columns: events['x'] = events['x'] * pitch_length / statsbomb_length
        if 'y' in events.columns: events['y'] = events['y'] * pitch_width / statsbomb_width
        if 'shot_end_location_x' in events.columns: events['shot_end_location_x'] = events['shot_end_location_x'] * pitch_length / statsbomb_length
        if 'shot_end_location_y' in events.columns: events['shot_end_location_y'] = events['shot_end_location_y'] * pitch_width / statsbomb_width

        if 'x' in tracking_match.columns: tracking_match['x'] = tracking_match['x'] * pitch_length / statsbomb_length
        if 'y' in tracking_match.columns: tracking_match['y'] = tracking_match['y'] * pitch_width / statsbomb_width
        # --- End Coordinate Standardization ---

        events['match_id'] = match_id
        if not tracking_match.empty:
            tracking_match['match_id'] = match_id

        # Append
        all_events_df = pd.concat([all_events_df, events], ignore_index=True)
        if not tracking_match.empty:
            all_tracking_df = pd.concat([all_tracking_df, tracking_match], ignore_index=True)

    except Exception as e:
        print(f"  Error processing match {match_id}: {e}")
        continue

loading_time = time.time() - start_time_section
print(f"\nFinished loading data in {loading_time:.2f} seconds.")

# Filter for Shots
shot_events_df = all_events_df[all_events_df["type_name"] == "Shot"].copy()
print(f"Total shot events found: {len(shot_events_df)}")
shot_events_df.dropna(subset=['x', 'y'], inplace=True) # Drop shots with missing location
print(f"Shot events after dropping NaN location: {len(shot_events_df)}")

# --- Visualization: Shot Type Distribution ---
plt.figure(figsize=(10, 5))
sns.countplot(data=shot_events_df, y='sub_type_name', order = shot_events_df['sub_type_name'].value_counts().index, palette='viridis')
plt.title('Distribution of Shot Sub-Types (Before Filtering)')
plt.xlabel('Count')
plt.ylabel('Shot Sub-Type')
plt.tight_layout()
plt.savefig(os.path.join(plot_dir, '1a_eda_shot_subtype_distribution.png'), bbox_inches='tight') # SAVE PLOT
plt.show()

# Filter for Open Play Shots
open_play_shots_df = shot_events_df[shot_events_df["sub_type_name"] == "Open Play"].copy()
print(f"Open play shots: {len(open_play_shots_df)}")

# --- Visualization: Open Play Shot Locations ---
pitch = Pitch(pitch_type='statsbomb', pitch_color='grass', line_color='white', stripe=True)
fig, ax = pitch.draw(figsize=(10, 7))
pitch.scatter(open_play_shots_df['x'], open_play_shots_df['y'], alpha=0.4, s=15, color='red', ax=ax)
ax.set_title('Locations of All Open Play Shots')
plt.savefig(os.path.join(plot_dir, '1b_eda_open_play_shot_locations.png'), bbox_inches='tight') # SAVE PLOT
plt.show()

print(f"--- Section 1 Runtime: {time.time() - start_time_section:.2f} seconds ---")

# %% [markdown]
# ## 2. Goalkeeper Tracking Filter
#
# Ensure that for the shots we consider, the opposition goalkeeper's position was tracked in the associated tracking data frame.

# %% [code]
start_time_section = time.time()

if not all_tracking_df.empty:
    # Identify events (shots) where the opposition GK was tracked
    gks_tracked_ids = all_tracking_df[
        (all_tracking_df["teammate"] == False) &
        (all_tracking_df["position_name"] == "Goalkeeper")
    ]['id'].unique() # Get the event IDs where opponent GK is present

    shots_pre_filter_count = len(open_play_shots_df)
    # Filter the open play shots to keep only those where the opponent GK was tracked
    shots_with_gk_df = open_play_shots_df[open_play_shots_df['id'].isin(gks_tracked_ids)].copy()
    shots_filtered_out = shots_pre_filter_count - len(shots_with_gk_df)

    print(f"Open play shots with tracked opponent GK: {len(shots_with_gk_df)}")
    print(f"(Filtered out {shots_filtered_out} shots due to missing opponent GK tracking in the same event frame)")

    # --- Visualization: Compare Shots Before/After GK Filter ---
    fig, axs = plt.subplots(1, 2, figsize=(16, 7))
    pitch.draw(ax=axs[0])
    pitch.scatter(open_play_shots_df['x'], open_play_shots_df['y'], alpha=0.2, s=10, color='blue', ax=axs[0])
    axs[0].set_title(f'All Open Play Shots ({shots_pre_filter_count})')

    pitch.draw(ax=axs[1])
    pitch.scatter(shots_with_gk_df['x'], shots_with_gk_df['y'], alpha=0.4, s=15, color='red', ax=axs[1])
    axs[1].set_title(f'Shots with Tracked Opponent GK ({len(shots_with_gk_df)})')
    plt.suptitle('Shot Locations Before and After Goalkeeper Tracking Filter')
    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap
    plt.savefig(os.path.join(plot_dir, '2_eda_gk_filter_comparison.png'), bbox_inches='tight') # SAVE PLOT
    plt.show()

    # Final dataframe for modeling
    df_model = shots_with_gk_df.reset_index(drop=True)
else:
    print("Error: Tracking data (all_tracking_df) is empty. Cannot filter based on Goalkeeper tracking.")
    df_model = pd.DataFrame() # Ensure df_model is empty

print(f"--- Section 2 Runtime: {time.time() - start_time_section:.2f} seconds ---")


# %% [markdown]
# ## 3. Feature Engineering & EDA on Features
#
# Calculate all features required for the model, including basic shot geometry, basic xG via logistic regression, and tracking-based features. Visualize the distributions and relationships of these features.

# %% [code]
start_time_section = time.time()

if not df_model.empty and not all_tracking_df.empty:
    print("\n--- Starting Feature Engineering ---")
    # Make a copy for feature engineering, selecting necessary columns
    # Added 'player_name', 'team_name' for later analysis plots if needed
    cols_to_keep = ['id', 'index', 'x', 'y', 'outcome_name', 'body_part_name',
                    'match_id', 'team_id', 'player_name', 'team_name', 'minute', 'second']
    cols_present = [col for col in cols_to_keep if col in df_model.columns]
    model_vars = df_model[cols_present].copy()

    # Target Variable (Goal = 1, No Goal = 0)
    model_vars["goal"] = model_vars.outcome_name.apply(lambda cell: 1 if cell == "Goal" else 0)

    # Basic Geometry (relative to goal at (105, 34))
    pitch_length = 105
    pitch_width = 68
    goal_width = 7.32
    model_vars["X_goal"] = pitch_length - model_vars["x"] # Distance to goal line
    model_vars["Y_goal_abs"] = abs(pitch_width/2 - model_vars["y"]) # Absolute distance from center y

    # Angle and Distance
    x_adj = np.maximum(0.01, model_vars["X_goal"])
    y_adj_sq = model_vars["Y_goal_abs"]**2
    term_in_arctan = (goal_width * x_adj) / (x_adj**2 + y_adj_sq - (goal_width/2)**2 + 1e-9) # Add epsilon for stability
    model_vars["angle"] = np.arctan(term_in_arctan) # Angle in radians
    model_vars["angle"] = np.where(model_vars["angle"] < 0, model_vars["angle"] + np.pi, model_vars["angle"]) # Correct angle range
    model_vars["angle_degrees"] = model_vars["angle"] * 180 / np.pi # Convert to degrees
    model_vars["distance"] = np.sqrt(x_adj**2 + y_adj_sq)

    # --- Calculate Basic Logistic Regression xG ('xg_basic') ---
    print("Calculating basic xG model...")
    try:
        log_reg_model = smf.glm(formula="goal ~ angle + distance", data=model_vars,
                                   family=sm.families.Binomial()).fit()
        model_vars["xg_basic"] = log_reg_model.predict(model_vars)
        print("Basic xG calculation complete.")
    except Exception as e:
        print(f"Error calculating basic xG model: {e}. Setting xg_basic to NaN.")
        model_vars["xg_basic"] = np.nan

    # --- Tracking-Based Features ---
    print("Calculating tracking-based features (this may take time)...")
    tracking_calc_start_time = time.time()

    # Group tracking data for faster lookups
    try:
      # Ensure 'id' columns are same type if needed (usually object/string is fine for UUIDs)
      # all_tracking_df['id'] = all_tracking_df['id'].astype(str)
      # model_vars['id'] = model_vars['id'].astype(str)
      tracking_grouped = all_tracking_df.groupby(['match_id', 'id'])
      print("Tracking data grouped.")
    except KeyError as e:
        print(f"Error grouping tracking data: Missing column {e}. Cannot calculate tracking features.")
        tracking_grouped = None # Set to None to skip calculations


    if tracking_grouped:
        # Helper functions (adapted slightly for clarity/efficiency)
        def get_tracking_slice(event_id, match_id, grouped_data):
            try:
                return grouped_data.get_group((match_id, event_id))
            except KeyError:
                return pd.DataFrame() # Return empty if event not in tracking

        def dist_to_gk(shot_row, grouped_tracking):
            tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
            if tracking_slice.empty: return np.nan
            gk_pos = tracking_slice[(tracking_slice['teammate'] == False) & (tracking_slice['position_name'] == 'Goalkeeper')]
            if gk_pos.empty: return np.nan
            gk_x, gk_y = gk_pos.iloc[0]['x'], gk_pos.iloc[0]['y']
            dist = np.sqrt((shot_row['x'] - gk_x)**2 + (shot_row['y'] - gk_y)**2)
            return dist

        def y_dist_to_gk(shot_row, grouped_tracking):
            tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
            if tracking_slice.empty: return np.nan
            gk_pos = tracking_slice[(tracking_slice['teammate'] == False) & (tracking_slice['position_name'] == 'Goalkeeper')]
            if gk_pos.empty: return np.nan
            gk_y = gk_pos.iloc[0]['y']
            dist = abs(shot_row['y'] - gk_y)
            return dist

        def num_opp_near_ball(shot_row, grouped_tracking, radius=3):
            tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
            if tracking_slice.empty: return 0
            # Exclude the GK from the count of nearby field players if desired
            opponents = tracking_slice[(tracking_slice['teammate'] == False) & (tracking_slice['position_name'] != 'Goalkeeper')]
            if opponents.empty: return 0
            distances = np.sqrt((shot_row['x'] - opponents['x'])**2 + (shot_row['y'] - opponents['y'])**2)
            return (distances < radius).sum()

        def players_in_triangle(shot_row, grouped_tracking):
            tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
            if tracking_slice.empty: return 0
            opponents = tracking_slice[tracking_slice['teammate'] == False]
            if opponents.empty: return 0

            p1 = np.array([shot_row['x'], shot_row['y']])
            p2 = np.array([pitch_length, pitch_width/2 - goal_width/2]) # Goal post 1
            p3 = np.array([pitch_length, pitch_width/2 + goal_width/2]) # Goal post 2

            def is_inside(point, v1, v2, v3):
                p = point
                d = (v2[1] - v3[1]) * (v1[0] - v3[0]) + (v3[0] - v2[0]) * (v1[1] - v3[1])
                if abs(d) < 1e-9: return False
                w1 = ((v2[1] - v3[1]) * (p[0] - v3[0]) + (v3[0] - v2[0]) * (p[1] - v3[1])) / d
                w2 = ((v3[1] - v1[1]) * (p[0] - v3[0]) + (v1[0] - v3[0]) * (p[1] - v3[1])) / d
                w3 = 1.0 - w1 - w2
                return (0 <= w1 <= 1) and (0 <= w2 <= 1) and (0 <= w3 <= 1)

            count = 0
            for _, opp in opponents.iterrows():
                opp_point = np.array([opp['x'], opp['y']])
                # Ensure opponent is between shooter and goal line before checking triangle
                if opp_point[0] > p1[0]:
                     if is_inside(opp_point, p1, p2, p3):
                         count += 1
            return count

        def gk_dist_to_goal_center(shot_row, grouped_tracking):
            tracking_slice = get_tracking_slice(shot_row['id'], shot_row['match_id'], grouped_tracking)
            if tracking_slice.empty: return np.nan
            gk_pos = tracking_slice[(tracking_slice['teammate'] == False) & (tracking_slice['position_name'] == 'Goalkeeper')]
            if gk_pos.empty: return np.nan
            gk_x, gk_y = gk_pos.iloc[0]['x'], gk_pos.iloc[0]['y']
            dist = np.sqrt((pitch_length - gk_x)**2 + (pitch_width/2 - gk_y)**2)
            return dist

        # Apply functions (can take a while)
        model_vars['gk_distance'] = model_vars.apply(dist_to_gk, grouped_tracking=tracking_grouped, axis=1)
        model_vars['gk_distance_y'] = model_vars.apply(y_dist_to_gk, grouped_tracking=tracking_grouped, axis=1)
        model_vars['close_players'] = model_vars.apply(num_opp_near_ball, grouped_tracking=tracking_grouped, radius=3, axis=1)
        model_vars['triangle'] = model_vars.apply(players_in_triangle, grouped_tracking=tracking_grouped, axis=1)
        model_vars['gk_dist_to_goal'] = model_vars.apply(gk_dist_to_goal_center, grouped_tracking=tracking_grouped, axis=1)

        # Handle potential NaNs from tracking calculations
        nan_track_cols = ['gk_distance', 'gk_distance_y', 'gk_dist_to_goal']
        for col in nan_track_cols:
            if model_vars[col].isnull().any():
                median_val = model_vars[col].median()
                print(f"Filling NaNs in '{col}' with median value: {median_val:.2f}")
                model_vars[col].fillna(median_val, inplace=True)

        # Derived tracking features
        model_vars['is_closer'] = np.where(model_vars['gk_dist_to_goal'] > model_vars['distance'], 1, 0)
        print(f"Tracking features calculated in {time.time() - tracking_calc_start_time:.2f} seconds.")

    else: # If tracking_grouped is None
         print("Skipping calculation of tracking-based features.")
         # Add columns with default values if they are expected later
         track_cols_default = ['gk_distance', 'gk_distance_y', 'close_players', 'triangle', 'gk_dist_to_goal', 'is_closer']
         for col in track_cols_default:
             if col not in model_vars.columns:
                 model_vars[col] = 0 # Or appropriate default (e.g., median from non-tracking data if possible)


    # Other features
    model_vars['header'] = model_vars.body_part_name.apply(lambda cell: 1 if cell == "Head" else 0)
    model_vars['x0'] = model_vars.x # Keep original x coordinate as a feature

    # Handle NaNs in xg_basic if calculation failed
    if model_vars["xg_basic"].isnull().any():
        median_xg_basic = model_vars["xg_basic"].median()
        print(f"Filling NaNs in 'xg_basic' with median value: {median_xg_basic:.4f}")
        model_vars["xg_basic"].fillna(median_xg_basic, inplace=True)


    # --- EDA on Engineered Features ---
    print("\n--- EDA on Engineered Features ---")

    # 1. Distributions of Key Continuous Features by Goal Outcome
    features_to_plot = ['angle_degrees', 'distance', 'xg_basic', 'gk_distance', 'gk_distance_y',
                        'gk_dist_to_goal', 'close_players', 'triangle']
    features_present = [f for f in features_to_plot if f in model_vars.columns] # Only plot if column exists
    if features_present:
        plot_rows = int(np.ceil(len(features_present) / 3))
        plt.figure(figsize=(15, plot_rows * 4))
        for i, col in enumerate(features_present):
            plt.subplot(plot_rows, 3, i + 1)
            sns.kdeplot(data=model_vars, x=col, hue='goal', fill=True, common_norm=False, palette='coolwarm', alpha=0.5, warn_singular=False)
            plt.title(f'Distribution of {col}')
            plt.ylabel('Density')
        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, '3a_eda_feature_distributions.png'), bbox_inches='tight') # SAVE PLOT
        plt.show()
    else:
        print("Skipping feature distribution plots as features are missing.")


    # 2. Counts of Binary/Categorical Features by Goal Outcome
    binary_features = ['is_closer', 'header']
    binary_features_present = [f for f in binary_features if f in model_vars.columns]
    if binary_features_present:
        plt.figure(figsize=(6 * len(binary_features_present), 4))
        for i, col in enumerate(binary_features_present):
            plt.subplot(1, len(binary_features_present), i + 1)
            sns.countplot(data=model_vars, x=col, hue='goal', palette='coolwarm')
            plt.title(f'Count of {col} by Goal Outcome')
        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, '3b_eda_binary_feature_counts.png'), bbox_inches='tight') # SAVE PLOT
        plt.show()
    else:
         print("Skipping binary feature count plots as features are missing.")


    # 3. Correlation Heatmap (including new features)
    corr_features = ['goal', 'angle', 'distance', 'xg_basic', 'gk_distance', 'gk_distance_y',
                     'close_players', 'triangle', 'gk_dist_to_goal', 'is_closer', 'header', 'x0']
    corr_features_exist = [f for f in corr_features if f in model_vars.columns and pd.api.types.is_numeric_dtype(model_vars[f])]
    if len(corr_features_exist) > 1:
        corr_matrix = model_vars[corr_features_exist].corr()
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
        plt.title('Correlation Matrix of Numeric Features')
        plt.savefig(os.path.join(plot_dir, '3c_eda_feature_correlation_heatmap.png'), bbox_inches='tight') # SAVE PLOT
        plt.show()
    else:
        print("Skipping correlation heatmap as not enough numeric features exist.")

    # 4. Shot Map colored by Number of Players in Triangle
    if 'triangle' in model_vars.columns:
        plt.figure(figsize=(10, 7))
        pitch = Pitch(pitch_type='statsbomb', pitch_color='grass', line_color='white', stripe=True)
        fig_tri, ax_tri = pitch.draw(figsize=(10, 7))
        sc = pitch.scatter(model_vars['x'], model_vars['y'], c=model_vars['triangle'], cmap='viridis_r', s=20, ax=ax_tri) # Reversed cmap
        cbar = fig_tri.colorbar(sc, ax=ax_tri)
        cbar.set_label('Number of Opponents in Triangle')
        ax_tri.set_title('Shot Locations Colored by Opponents in Triangle')
        plt.savefig(os.path.join(plot_dir, '3d_eda_shot_map_opp_triangle.png'), bbox_inches='tight') # SAVE PLOT
        plt.show()
    else:
        print("Skipping shot map by triangle as 'triangle' feature is missing.")


    print(f"--- Section 3 Runtime: {time.time() - start_time_section:.2f} seconds ---")

else:
    print("\nSkipping Feature Engineering as input dataframes (df_model or all_tracking_df) are empty.")
    model_vars = pd.DataFrame() # Ensure empty for downstream


# %% [markdown]
# ## 4. Data Preparation for Model
#
# Select the final features, define the target variable, split the data into training, validation, and test sets (preserving original indices), and scale the features.

# %% [code]
start_time_section = time.time()

if not model_vars.empty:
    # Define features (X) and target (y)
    feature_names = ["x0", "is_closer", "angle", "distance", "gk_distance",
                     "gk_distance_y", "triangle", "close_players", "header", "xg_basic"]

    # Check if all feature names exist in model_vars columns before selection
    missing_features = [f for f in feature_names if f not in model_vars.columns]
    if missing_features:
        print(f"Error: The following required features are missing from model_vars: {missing_features}")
        print("Cannot proceed with model training preparation.")
        # Set flags/variables to prevent downstream execution
        data_prepared = False
    else:
        X_df = model_vars[feature_names] # Keep as DataFrame temporarily for index
        y = model_vars["goal"].values
        original_indices = X_df.index # Get original indices NOW

        print(f"Feature matrix shape (before numpy conversion): {X_df.shape}")
        print(f"Target vector shape: {y.shape}")

        # Convert features to NumPy array for splitting and scaling
        X = X_df.values

        # Split data AND original indices: 70% train, 15% validation, 15% test
        X_train, X_temp, y_train, y_temp, idx_train, idx_temp = train_test_split(
            X, y, original_indices, test_size=0.3, random_state=SEED, stratify=y
        )
        X_val, X_test, y_val, y_test, idx_val, idx_test = train_test_split(
            X_temp, y_temp, idx_temp, test_size=0.5, random_state=SEED, stratify=y_temp
        )
        # Now idx_test holds the original indices for the test set

        print(f"Train samples: {len(X_train)}")
        print(f"Validation samples: {len(X_val)}")
        print(f"Test samples: {len(X_test)}")
        print(f"Test indices count: {len(idx_test)}") # Verify count matches X_test

        # Scale data
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_val = scaler.transform(X_val)
        X_test = scaler.transform(X_test)
        print("Data scaling complete.")
        data_prepared = True # Flag successful preparation

else:
    print("Skipping Data Preparation as model_vars is empty.")
    data_prepared = False

print(f"--- Section 4 Runtime: {time.time() - start_time_section:.2f} seconds ---")

# %% [markdown]
# ## 5. Model Definition & Training (Keras Neural Network)
#
# Define and train the shallow neural network using Keras, similar to the original notebook. Optimize for Mean Squared Error (Brier Score).

# %% [code]
start_time_section = time.time()

if data_prepared: # Check if data preparation was successful
    print("\n--- Defining and Training Neural Network Model ---")

    # Define model architecture
    def create_model(input_shape):
        model = Sequential([
            Dense(10, activation='relu', input_shape=(input_shape,)),
            Dense(10, activation='relu'),
            Dense(1, activation='sigmoid'), # Output probability
        ])
        # Compile using Adam optimizer and MSE loss (equivalent to Brier score for binary 0/1 target)
        opt = Adam(learning_rate=0.001) # Default betas are fine
        model.compile(optimizer=opt, loss="mean_squared_error", metrics=['binary_accuracy']) # Use binary_accuracy for intuition
        return model

    # Create the model
    input_dim = X_train.shape[1]
    model = create_model(input_dim)
    print(model.summary())

    # Define Early Stopping callback
    early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=50,
                                   verbose=1, mode='min', restore_best_weights=True)

    # Train the model
    BATCH_SIZE = 64 # Adjusted batch size
    EPOCHS = 500 # Max epochs, early stopping will likely trigger sooner

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        callbacks=[early_stopping],
        verbose=2 # Show less output per epoch
    )

    print(f"--- Model Training Finished ---")

    # --- Visualization: Training History ---
    hist_df = pd.DataFrame(history.history)
    fig_hist, axs_hist = plt.subplots(1, 2, figsize=(14, 5))

    # Plot Loss
    axs_hist[0].plot(hist_df['loss'], label='Train Loss')
    axs_hist[0].plot(hist_df['val_loss'], label='Validation Loss')
    axs_hist[0].set_title('Model Loss (MSE / Brier Score)')
    axs_hist[0].set_xlabel('Epoch')
    axs_hist[0].set_ylabel('Loss')
    axs_hist[0].legend()
    axs_hist[0].grid(True, alpha=0.3)
    # Highlight best epoch based on validation loss
    best_epoch = np.argmin(hist_df['val_loss'])
    axs_hist[0].axvline(best_epoch, color='r', linestyle='--', label=f'Best Epoch ({best_epoch+1})')
    axs_hist[0].legend()


    # Plot Accuracy
    axs_hist[1].plot(hist_df['binary_accuracy'], label='Train Accuracy')
    axs_hist[1].plot(hist_df['val_binary_accuracy'], label='Validation Accuracy')
    axs_hist[1].set_title('Model Accuracy')
    axs_hist[1].set_xlabel('Epoch')
    axs_hist[1].set_ylabel('Accuracy')
    axs_hist[1].legend()
    axs_hist[1].grid(True, alpha=0.3)
    # Highlight epoch with best validation accuracy
    best_acc_epoch = np.argmax(hist_df['val_binary_accuracy'])
    axs_hist[1].axvline(best_acc_epoch, color='g', linestyle='--', label=f'Best Acc Epoch ({best_acc_epoch+1})')
    axs_hist[1].legend()

    plt.tight_layout()
    plt.savefig(os.path.join(plot_dir, '5_model_training_history.png'), bbox_inches='tight') # SAVE PLOT
    plt.show()
    model_trained = True

else:
    print("Skipping Model Training as prepared data is not available.")
    model_trained = False

print(f"--- Section 5 Runtime: {time.time() - start_time_section:.2f} seconds ---")

# %% [markdown]
# ## 6. Model Evaluation on Test Set
#
# Evaluate the trained model's performance on the unseen test set using various metrics and visualizations.

# %% [code]
start_time_section = time.time()

if model_trained: # Check if model was trained successfully
    print("\n--- Evaluating Model on Test Set ---")

    # Predict probabilities on the test set
    y_pred_proba = model.predict(X_test).flatten() # Flatten to 1D array
    y_pred_class = (y_pred_proba > 0.5).astype(int) # Class prediction based on 0.5 threshold

    # --- Calculate Metrics ---
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    brier = brier_score_loss(y_test, y_pred_proba)
    logloss = log_loss(y_test, y_pred_proba) # Use log loss for probabilities
    accuracy = np.mean(y_pred_class == y_test)

    print(f"Test Set Metrics:")
    print(f"  ROC AUC: {roc_auc:.4f}")
    print(f"  Brier Score: {brier:.4f}")
    print(f"  Log Loss: {logloss:.4f}")
    print(f"  Accuracy: {accuracy:.4f}")

    # --- Visualizations ---
    fig_eval, axs_eval = plt.subplots(2, 2, figsize=(14, 12))

    # 1. ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    axs_eval[0, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')
    axs_eval[0, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance')
    axs_eval[0, 0].set_xlim([0.0, 1.0])
    axs_eval[0, 0].set_ylim([0.0, 1.05])
    axs_eval[0, 0].set_xlabel('False Positive Rate')
    axs_eval[0, 0].set_ylabel('True Positive Rate')
    axs_eval[0, 0].set_title('Receiver Operating Characteristic (ROC)')
    axs_eval[0, 0].legend(loc="lower right")
    axs_eval[0, 0].grid(alpha=0.3)

    # 2. Precision-Recall Curve
    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
    pr_auc = auc(recall, precision)
    axs_eval[0, 1].plot(recall, precision, color='blue', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')
    baseline = y_test.mean() # Baseline: ratio of positive class
    axs_eval[0, 1].axhline(baseline, ls='--', color='grey', label=f'Baseline ({baseline:.3f})')
    axs_eval[0, 1].set_xlabel('Recall')
    axs_eval[0, 1].set_ylabel('Precision')
    axs_eval[0, 1].set_title('Precision-Recall Curve')
    axs_eval[0, 1].legend(loc="upper right")
    axs_eval[0, 1].grid(alpha=0.3)
    axs_eval[0, 1].set_ylim([0.0, 1.05])
    axs_eval[0, 1].set_xlim([0.0, 1.0])

    # 3. Calibration Curve
    prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10, strategy='uniform')
    axs_eval[1, 0].plot(prob_pred, prob_true, marker='o', linestyle='-', label='Model Calibration', color='red')
    axs_eval[1, 0].plot([0, 1], [0, 1], linestyle='--', color='black', label='Perfectly Calibrated')
    axs_eval[1, 0].set_xlabel('Mean Predicted Probability (Bin)')
    axs_eval[1, 0].set_ylabel('Fraction of Positives (Bin)')
    axs_eval[1, 0].set_title('Calibration Curve')
    axs_eval[1, 0].legend()
    axs_eval[1, 0].grid(alpha=0.3)

    # 4. Distribution of Predicted Probabilities (xG)
    sns.histplot(y_pred_proba[y_test==0], color="red", label="No Goal", kde=True, stat="density", linewidth=0, alpha=0.4, ax=axs_eval[1, 1])
    sns.histplot(y_pred_proba[y_test==1], color="blue", label="Goal", kde=True, stat="density", linewidth=0, alpha=0.4, ax=axs_eval[1, 1])
    axs_eval[1, 1].set_title('Distribution of Predicted xG Values by Outcome')
    axs_eval[1, 1].set_xlabel('Predicted xG Probability')
    axs_eval[1, 1].legend()
    axs_eval[1, 1].set_xlim(0, max(0.6, y_pred_proba.max() * 1.05)) # Adjust xlim dynamically or set fixed e.g., 0.6

    plt.tight_layout()
    plt.savefig(os.path.join(plot_dir, '6_model_evaluation_plots.png'), bbox_inches='tight') # SAVE PLOT
    plt.show()
    evaluation_done = True

else:
    print("Skipping Model Evaluation as model was not trained.")
    evaluation_done = False

print(f"--- Section 6 Runtime: {time.time() - start_time_section:.2f} seconds ---")


# %% [markdown]
# ## 7. Qualitative Analysis & Examples
#
# Visualize specific examples from the test set on a pitch, showing player positions from tracking data and the model's predicted xG. This helps understand *why* the model assigns certain probabilities.

# %% [code]
start_time_section = time.time()

if evaluation_done and 'idx_test' in locals() and not model_vars.empty and 'tracking_grouped' in locals() and tracking_grouped is not None:
    print("\n--- Qualitative Analysis: Plotting Example Shots ---")

    # Get original data corresponding to the test set using the saved indices
    test_indices = idx_test # Use the indices saved during split
    test_data_orig = model_vars.loc[test_indices].copy()
    test_data_orig['predicted_xg'] = y_pred_proba

    # Find examples: Highest xG miss, Lowest xG goal
    misses_test = test_data_orig[test_data_orig['goal'] == 0]
    goals_test = test_data_orig[test_data_orig['goal'] == 1]

    examples_to_plot_list = []
    if not misses_test.empty:
        highest_xg_miss = misses_test.sort_values('predicted_xg', ascending=False).head(3) # Get top 3 misses
        examples_to_plot_list.append(highest_xg_miss)
    else:
        print("Warning: No misses found in the test set for qualitative examples.")

    if not goals_test.empty:
        lowest_xg_goal = goals_test.sort_values('predicted_xg', ascending=True).head(3) # Get top 3 goals
        examples_to_plot_list.append(lowest_xg_goal)
    else:
        print("Warning: No goals found in the test set for qualitative examples.")

    if examples_to_plot_list:
        examples_to_plot = pd.concat(examples_to_plot_list)
        print(f"Plotting {len(examples_to_plot)} examples...")

        pitch = Pitch(pitch_type='statsbomb', pitch_color='#22312b', line_color='#c7d5cc')

        for i, shot_info in examples_to_plot.iterrows():
            match_id = shot_info['match_id']
            # Ensure event_id is suitable for filename
            event_id = str(shot_info['id']).replace('-', '_') # Basic sanitization for filename
            goal_outcome = "GOAL" if shot_info['goal'] == 1 else "NoGoal"
            predicted_xg_val = shot_info['predicted_xg']

            try:
                # Use original ID for lookup (ensure type consistency if needed)
                tracking_slice = tracking_grouped.get_group((match_id, shot_info['id']))

                fig_ex, ax_ex = pitch.draw(figsize=(12, 8))
                fig_ex.set_facecolor('#22312b')

                # Plot players
                # Ensure 'teammate' column exists, otherwise fallback might be needed if implemented
                if 'teammate' in tracking_slice.columns:
                     teammates_track = tracking_slice[tracking_slice['teammate']]
                     opponents_track = tracking_slice[~tracking_slice['teammate']]
                else:
                     # Fallback logic (requires shot_info['team_id'] and tracking_slice['team_id']) - Implement if needed
                     print("Warning: 'teammate' column missing in tracking slice for example plot.")
                     # Example fallback (untested, requires team_id in tracking):
                     # event_team_id = shot_info['team_id']
                     # teammates_track = tracking_slice[tracking_slice['team_id'] == event_team_id]
                     # opponents_track = tracking_slice[tracking_slice['team_id'] != event_team_id]
                     continue # Skip plot if teammate info missing


                pitch.scatter(teammates_track['x'], teammates_track['y'], c='blue', edgecolors='w', s=150, label='Shooter Team', ax=ax_ex, zorder=3)
                pitch.scatter(opponents_track['x'], opponents_track['y'], c='red', edgecolors='w', s=150, label='Opponent Team', ax=ax_ex, zorder=3)

                # Highlight shooter
                shooter_x, shooter_y = shot_info['x'], shot_info['y']
                pitch.scatter(shooter_x, shooter_y, c='yellow', edgecolors='k', s=250, marker='*', label='Shooter', ax=ax_ex, zorder=4)

                # Line to center of goal
                pitch_length = 105 # Define pitch length if not globally available here
                pitch_width = 68  # Define pitch width
                pitch.lines(shooter_x, shooter_y, pitch_length, pitch_width/2, color='yellow', lw=2, ls='--', ax=ax_ex, label='Path to Goal Center', zorder=2)

                # Add title
                player_name = shot_info.get('player_name', 'N/A')
                team_name = shot_info.get('team_name', 'N/A')
                title_text = (f"Example Shot: Match {match_id}\n{player_name} ({team_name})\n"
                              f"Outcome: {goal_outcome}, Predicted xG: {predicted_xg_val:.3f}")
                ax_ex.set_title(title_text, color='white', fontsize=14)
                ax_ex.legend(loc='center left', bbox_to_anchor=(1, 0.5), facecolor='grey', edgecolor='white', labelcolor='white')

                # --- Save the plot ---
                plot_filename = f"7_example_shot_{goal_outcome}_xg{predicted_xg_val:.3f}_match{match_id}_event{event_id}.png"
                save_path = os.path.join(plot_dir, plot_filename)
                try:
                    plt.savefig(save_path, bbox_inches='tight', facecolor=fig_ex.get_facecolor())
                    print(f"Saved example plot: {save_path}")
                except Exception as save_err:
                    print(f"Error saving plot {save_path}: {save_err}")
                # --- End Save ---
                plt.show() # Display plot after saving
                plt.close(fig_ex) # Close the figure to free memory

            except KeyError:
                print(f"Warning: Could not find tracking data for example shot (Match {match_id}, Event {shot_info['id']}). Skipping plot.")
            except Exception as e:
                print(f"Error plotting example shot (Match {match_id}, Event {shot_info['id']}): {e}")
    else:
        print("No examples found to plot (likely due to no goals or no misses in the test set).")

else:
    print("Skipping Qualitative Analysis as prerequisites (model evaluation, indices, data) are missing.")

print(f"--- Section 7 Runtime: {time.time() - start_time_section:.2f} seconds ---")


# %% [markdown]
# ## 8. (Optional) Application on New Data (Euro 2020 Example)
#
# Apply the trained model (including the scaler) to a different dataset (e.g., Euro 2020) to calculate xG values. Note: Euro 2020 uses freeze frames, so tracking features need careful adaptation or omission if not directly comparable. *For simplicity here, we might need to skip some tracking features or use default values if applying to Euro.*
#
# **Note:** Due to the differences in tracking data availability (ISL tracking vs Euro freeze frames), directly applying all tracking features might be problematic. A robust application would require recalculating features based *only* on freeze frames for the Euro data, or training a separate model. This section is illustrative and may require adjustments.

# %% [code]
# --- Optional Section ---
# Commenting out for now as applying ISL tracking features to Euro freeze frames requires careful adaptation.
"""
# [ CODE FROM PREVIOUS VERSION FOR EURO APPLICATION - REQUIRES ADAPTATION ]
"""
print("\nSkipping Optional Euro 2020 Application section.")

# %% [markdown]
# ## 9. Conclusion
#
# Summarize the findings from the enhanced xG model. Discuss the impact of tracking features, model performance (AUC, Brier, Calibration), and insights gained from the improved visualizations and qualitative examples. Potential next steps could include trying different model architectures, adding more sophisticated tracking features (e.g., player velocity, line-breaking passes leading to the shot), or applying the model for player/team evaluation.

# %% [code]
print("\n--- Notebook Execution Complete ---")
total_runtime = time.time() - start_time_notebook
print(f"Total Runtime: {total_runtime:.2f} seconds ({total_runtime/60:.2f} minutes)")

